hadoop是一个分布式系统基础架构


用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储

hadoop实现了一个分布式文件系统(HDFS).HDFS有高容错性的特点，并且设计用来部署再低廉(low-cost)的硬件上；
而且它提供高吞吐量(high throughtput)来访问应用程序的数据，适合那些有着超大数据集(large data set)的应用
程序。HDFS放宽了(relax)POSIX的要求，可以以流的形式访问(streaming access)文件系统中的数据

hadoop的框架最核心的设计就是：HDFS和MapReduce.

HDFS为海量的数据提供存储
MapReduce则为海量的数据提供了计算

hadoop是一个能够对大量数据进行分布式处理的软件框架。hadoop以一种可靠，高效，可伸缩的方式
进行数据处理


hadoop是可靠的，因为它假设计算元素和存储失败，因为它维护多个工作数据
副本，确保能够针对失败的节点重新分布处理


hadoop是高效的，因为它以并行的方式工作，通过并行处理加快处理速度

hadoop还是可伸缩的，能够处理PB级数据


此外，hadoop依赖与社区服务，因为它的成本比较低，任何人都可以使用
hadoop是一个能够让用户轻松架构和使用的分布式计算平台。用户可以轻松
地再hadoop上开发和运行处理海量数据的应用程序。它主要的几个优点：
1.高可靠性。hadoop按位存储和处理数据的能力值得人们信赖
2.高扩展性。hadoop是在可用的计算机集簇间分配数据并计算任务的，
这些集簇可以方便地扩展到数以千计的节点中
3.高效性。hadoop能够再节点之间动态地移动数据，并保证各个节点的动态
平衡，因此处理速度非常快
4. 高容错性。hadoop能够自动保存数据的多个副本，并且能够自动将失败的
任务重新分配
5.低成本。与一体机，商用数据仓库以及QlikView，Yonghong Z-Suite
等数据集市相比，hadoop是开源的，项目的软件成本因此会大大降低

hadoop带有用java编写的框架爱，在linux生产平台上非常理想
hadoop上的应用程序也可以使用其他语言编写，比如c++

hadoop大数据处理的意义

hadoop得以再大数据处理应用中广泛应用得益于其自身再数据提取，
变形和加载(ETL)方面上的天然优势。
Hadoop的分布式架构，将大数据处理引擎尽可能的靠近存储，对例如
像ETL这样的批处理操作相对合适，因为类似这样操作的批处理结果可以直接
走向存储

hadoop的MapReduce功能实现了将单个任务打碎，并将碎片任务(Map)
发送到多个节点上，之后再以单个数据集的形式加载(Reduce)到数据仓库立
核心架构


hadoop由许多元素构成。其最底部是(HDFS),它存储hadoop集群中
素有存储节点上的文件。

HDFS(对于文本)上一层是MapReduce引擎，该引擎由JobTrackers和
TaskTrackers组成。通过对Hadoop分布式计算平台最核心的分布式
文件系统HDFS,MapReduce处理过程，以及数据仓库工具Hive
和分布式数据库Hbase的介绍，基本涵盖了Hadoop分布式平台的所有技术核心


HDFS

对外部客户机而言，HDFS就像一个传统的分级文件系统。可以创建，
删除，移动或重命名文件，等等。但是HDFS的架构
是基于一组特定的节点构建的，这是由它自身的特点决定的。
这些节点包括NameNode(仅一个)，它在HDFS内部提供元数据服务；
DataNode,它为HDFS提供存储块。由于仅存再一个NameNode,
因此这是HDFS的一个缺点(单点失败)


存储在HDFS中的文件被分成块，然后将这些块复制到多个计算机中(DataNode).
这与传统的RAID架构大不相同。块的大小(通常为64MB)和复制的块
数量在创建文件时由客户机决定。NameNode可以控制所有文件操作。
HDFS内部的所有通信都基于标准的TCP/IP协议

NameNode
NameNode是一个通常再HDFS中的单独机器上运行的软件。它负责文件系统
名称空间和控制外部客户机的访问。NameNode决定是否将文件映射到
DataNode上的复制块上。

实际的 I/O事务并没有经过 NameNode，只有表示 DataNode 和块的文件映射的元数据经过 NameNode。当外部客户机发送请求要求创建文件时，NameNode 会以块标识和该块的第一个副本的 DataNode IP 地址作为响应。这个 NameNode 还会通知其他将要接收该块的副本的 DataNode。
NameNode 在一个称为 FsImage 的文件中存储所有关于文件系统名称空间的信息。这个文件和一个包含所有事务的记录文件（这里是 EditLog）将存储在 NameNode 的本地文件系统上。FsImage 和 EditLog 文件也需要复制副本，以防文件损坏或 NameNode 系统丢失。
NameNode本身不可避免地具有SPOF（Single Point Of Failure）单点失效的风险，主备模式并不能解决这个问题，通过Hadoop Non-stop namenode才能实现100% uptime可用时间。


DataNode
DataNode也是一个通常在HDFS实例中的单独机器上运行的软件。

hadoop集群包含一个NameNode和大量DataNode.

DataNode通常以机架的形式组织，机架通过一个交换机将
所有系统连接起来。
hadoop的一个假设是：机架内部节点之间的传输速度快于
机架间节点的传输速度

DataNode响应来自HDFS客户机的读写请求。它们还响应来自 NameNode 的创建、删除和复制块的命令。NameNode 依赖来自每个 DataNode 的定期心跳（heartbeat）消息。每条消息都包含一个块报告，NameNode 可以根据这个报告验证块映射和其他文件系统元数据。如果 DataNode 不能发送心跳消息，NameNode 将采取修复措施，重新复制在该节点上丢失的块。

文件操作

HDFS的主要目的是支持以流的形式访问写入的大型文件

如果客户机想将文件写到 HDFS 上，首先需要将该文件缓存到本地的临时存储。如果缓存的数据大于所需的 HDFS 块大小，创建文件的请求将发送给 NameNode。NameNode 将以 DataNode 标识和目标块响应客户机。
同时也通知将要保存文件块副本的 DataNode。当客户机开始将临时文件发送给第一个 DataNode 时，将立即通过管道方式将块内容转发给副本 DataNode。客户机也负责创建保存在相同 HDFS名称空间中的校验和（checksum）文件。
在最后的文件块发送之后，NameNode 将文件创建提交到它的持久化元数据存储（在 EditLog 和 FsImage 文件）。


linux集群


Hadoop 框架可在单一的 Linux 平台上使用（开发和调试时），官方提供MiniCluster作为单元测试使用，不过使用存放在机架上的商业服务器才能发挥它的力量。这些机架组成一个 Hadoop 集群。它通过集群拓扑知识决定如何在整个集群中分配作业和文件。Hadoop 假定节点可能失败，因此采用本机方法处理单个计算机甚至所有机架的失败。

hadoop和高效能计算，网格计算的区别


Hadoop 使用专门为分布式计算设计的文件系统HDFS，计算的时候只需要将计算代码推送到存储节点上，即可在存储节点上完成数据本地化计算，Hadoop 中的集群存储节点也是计算节点。



网格计算通常是指通过现有的互联网，利用大量来自不同地域、资源异构的计算机空闲的CPU 和磁盘来进行分布式存储和计算。这些参与计算的计算机具有分处不同地域、资源异构（基于不同平台，使用不同的硬件体系结构等）等特征，从而使网格计算和Hadoop 这种基于集群的计算相区别开。Hadoop 集群一般构建在通过高速网络连接的单一数据中心内，集群计算机都具有体系结构、平台一致的特点，而网格计算需要在互联网接入环境下使用，网络带宽等都没有保证。

MapReduce与Hadoop之比较


hadoop是一种分布式数据和计算的框架。非常擅长分布式计算---
快速地跨多台机器处理大型数据集合。

MapReduce是处理大量半结构化数据集合的编程模型。编程模型是一种处理病
结构化特定问题的方式。例如，在一个关系数据库中，使用一种集合
语言执行查询，如sql.

告诉语言想要的结果，并将它提交给系统来计算如何产生计算。
还可以用传统的语言(c++,java),一步一步地解决问题。这是两种不同的编程模型，MapReduce就是另外一种。
MapReduce和Hadoop是相互独立的，实际上又能相互配合工作得很好。

集群系统
Google的基础设施，核心组件有3个：

1.GFS(Google File System).
一个分布式文件系统，隐藏下层负载均衡，冗余复制等细节，对上层
程序提供一个统一文件系统API借口。

2.MapReduce。Google发现大多数分布式运算可以抽象为MapReduce操作


Map是把输入Input分解成中间的Key/Value对，
Reduce把Key/Value合成最终输出Output,这两个函数由程序员
提供给系统，下层设施把Map和Reduce操作分布在集群上运行，
并把结果存储在GFS上。

3. BigTable.一个大型的分布式数据库，这个数据库不是关系式
的数据库。就是一个巨大的表格，用来存储结构化的数据

应用程序

hadoop最常见的用法是web搜索。


HDFS是Google File System(GFS)的开源实现

Hadoop实现了HDFS文件系统和MapReduce。用户只要继承MapReduceBase，提供分别实现Map和Reduce的两个类，并注册Job即可自动分布式运行。

HDFS把节点分成两类：NameNode和DataNode。NameNode是唯一的，程序与之通信，然后从DataNode上存取文件。这些操作是透明的，与普通的文件系统API没有区别。
MapReduce则是JobTracker节点为主，分配工作以及负责和用户程序通信。
HDFS和MapReduce实现是完全分离的，并不是没有HDFS就不能MapReduce运算。

Hadoop也跟其他云计算项目有共同点和目标：实现海量数据的计算。而进行海量计算需要一个稳定的，安全的数据容器，才有了Hadoop分布式文件系统（HDFS，Hadoop Distributed File System）。
HDFS通信部分使用org.apache.hadoop.ipc，可以很快使用RPC.Server.start()构造一个节点，具体业务功能还需自己实现。针对HDFS的业务则为数据流的读写，NameNode/DataNode的通信等。
MapReduce主要在org.apache.hadoop.mapred，实现提供的接口类，并完成节点通信（可以不是hadoop通信接口），就能进行MapReduce运算。


HDFS: Hadoop分布式文件系统(Distributed File System) － HDFS (Hadoop Distributed File System)
MapReduce：并行计算框架，0.20前使用 org.apache.hadoop.mapred 旧接口，0.20版本开始引入org.apache.hadoop.mapreduce的新API
HBase: 类似Google BigTable的分布式NoSQL列数据库。（HBase和Avro已经于2010年5月成为顶级 Apache 项目）
Hive：数据仓库工具，由Facebook贡献。
Zookeeper：分布式锁设施，提供类似Google Chubby的功能，由Facebook贡献。
Avro：新的数据序列化格式与传输工具，将逐步取代Hadoop原有的IPC机制。
Pig: 大数据分析平台，为用户提供多种接口。
Ambari：Hadoop管理工具，可以快捷的监控、部署、管理集群。
Sqoop：于在HADOOP与传统的数据库间进行数据的传递。


